{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this code gets only the images to trian the pre-trained model using the cross validation technique\n",
    "\n",
    "# use this cell to import all necessary libraries\n",
    "\n",
    "import os\n",
    "# to run on GPU, comment the following tow lines \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pylab\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from util_pre import read_data\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to get all of the input parameters and paths to train and tune\n",
    "\n",
    "# input parameters and paths for training\n",
    "\n",
    "csvPath = '/home/mohammadali/Downloads/Run/Train.csv'\n",
    "imagePath = '/home/mohammadali/Downloads/Run/Train-Seg-Man'\n",
    "inputSize = (224,224)\n",
    "k_fold = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-6\n",
    "epoch_size = 3\n",
    "nodes = 1024 # number of nodes for the fc layer\n",
    "drop_out = 0.1 # the layer after the fc layer\n",
    "\n",
    "# input parameters and paths for testing\n",
    "\n",
    "test_dir = '/home/mohammadali/Downloads/Run/Test-Seg-Man'\n",
    "csvTest = '/home/mohammadali/Downloads/Run/Test.csv'\n",
    "IMG_SIZE = 224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: 50 positive,45 negatve.\n",
      "Split dataset according to images. Training : 564 images; Validation: 6 images.\n",
      "\n",
      "using images\n",
      "\n",
      "train_images: (564, 224, 224, 3)\n",
      "train_labels: (564,)\n",
      "\n",
      "getting the model\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "fold 1:\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 5s 364ms/step - loss: 0.7479 - acc: 0.4750 - val_loss: 0.7329 - val_acc: 0.4912\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 2s 165ms/step - loss: 0.7162 - acc: 0.5068 - val_loss: 0.7220 - val_acc: 0.4737\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 3s 222ms/step - loss: 0.7168 - acc: 0.5099 - val_loss: 0.7077 - val_acc: 0.5263\n",
      "acc: 52.63%\n",
      "auc: 49.14%\n",
      "\n",
      "fold 2:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 254ms/step - loss: 0.6968 - acc: 0.5542 - val_loss: 0.7011 - val_acc: 0.5263\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.6829 - acc: 0.5759 - val_loss: 0.6954 - val_acc: 0.5263\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.7039 - acc: 0.5377 - val_loss: 0.6903 - val_acc: 0.5789\n",
      "acc: 57.89%\n",
      "auc: 58.89%\n",
      "\n",
      "fold 3:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 259ms/step - loss: 0.6932 - acc: 0.5250 - val_loss: 0.6654 - val_acc: 0.6667\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.6631 - acc: 0.5853 - val_loss: 0.6631 - val_acc: 0.5614\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.6506 - acc: 0.6301 - val_loss: 0.6560 - val_acc: 0.5439\n",
      "acc: 54.39%\n",
      "auc: 71.98%\n",
      "\n",
      "fold 4:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 259ms/step - loss: 0.6582 - acc: 0.6125 - val_loss: 0.6046 - val_acc: 0.6842\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 238ms/step - loss: 0.6585 - acc: 0.6301 - val_loss: 0.5973 - val_acc: 0.7193\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.6433 - acc: 0.6281 - val_loss: 0.5910 - val_acc: 0.7719\n",
      "acc: 77.19%\n",
      "auc: 83.58%\n",
      "\n",
      "fold 5:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.6419 - acc: 0.6438 - val_loss: 0.5946 - val_acc: 0.7321\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.6396 - acc: 0.6488 - val_loss: 0.5858 - val_acc: 0.7500\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.6297 - acc: 0.6625 - val_loss: 0.5772 - val_acc: 0.7500\n",
      "acc: 75.00%\n",
      "auc: 82.31%\n",
      "\n",
      "fold 6:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 256ms/step - loss: 0.6014 - acc: 0.7000 - val_loss: 0.6207 - val_acc: 0.6964\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 237ms/step - loss: 0.5948 - acc: 0.7349 - val_loss: 0.6178 - val_acc: 0.6964\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.6137 - acc: 0.6819 - val_loss: 0.6159 - val_acc: 0.6786\n",
      "acc: 67.86%\n",
      "auc: 72.69%\n",
      "\n",
      "fold 7:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 255ms/step - loss: 0.5864 - acc: 0.7021 - val_loss: 0.5558 - val_acc: 0.7500\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.5922 - acc: 0.6950 - val_loss: 0.5532 - val_acc: 0.7321\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.5794 - acc: 0.6955 - val_loss: 0.5471 - val_acc: 0.7321\n",
      "acc: 73.21%\n",
      "auc: 81.41%\n",
      "\n",
      "fold 8:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 254ms/step - loss: 0.5864 - acc: 0.7000 - val_loss: 0.5320 - val_acc: 0.7857\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.5602 - acc: 0.7276 - val_loss: 0.5258 - val_acc: 0.7857\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 0.5676 - acc: 0.7292 - val_loss: 0.5209 - val_acc: 0.8036\n",
      "acc: 80.36%\n",
      "auc: 84.87%\n",
      "\n",
      "fold 9:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 256ms/step - loss: 0.5729 - acc: 0.6917 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 3s 232ms/step - loss: 0.5569 - acc: 0.7237 - val_loss: 0.5486 - val_acc: 0.7143\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 3s 233ms/step - loss: 0.5382 - acc: 0.7458 - val_loss: 0.5477 - val_acc: 0.7143\n",
      "acc: 71.43%\n",
      "auc: 80.77%\n",
      "\n",
      "fold 10:\n",
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 253ms/step - loss: 0.5421 - acc: 0.7438 - val_loss: 0.5111 - val_acc: 0.7500\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 4s 234ms/step - loss: 0.5733 - acc: 0.7262 - val_loss: 0.5056 - val_acc: 0.7321\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 240ms/step - loss: 0.5251 - acc: 0.7493 - val_loss: 0.5033 - val_acc: 0.7679\n",
      "acc: 76.79%\n",
      "auc: 84.10%\n",
      "\n",
      "tot_acc_avg: 68.67% (+/- 9.60%)\n",
      "tot_auc_avg: 74.97% (+/- 11.51%)\n"
     ]
    }
   ],
   "source": [
    "# use this cell to train the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# preparing the data to train\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "train_img,train_label,val_img,val_label = read_data(csvPath,\n",
    "        imagePath, inputSize, 0.00001, split_by_id=False, normalize=True, crop_image=True)\n",
    "train_img = np.stack( (train_img[:,:,:,0],)*3, axis=-1 )\n",
    "X = train_img\n",
    "y = train_label\n",
    "\n",
    "print(\"\")\n",
    "print(\"using images\")\n",
    "print(\"\")\n",
    "print(\"train_images:\", train_img.shape)\n",
    "print(\"train_labels:\", train_label.shape)\n",
    "#print(\"validation_images:\", val_img.shape)\n",
    "#print(\"validation_label:\", val_label.shape)\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "print(\"\")\n",
    "print(\"getting the model\")\n",
    "print(\"\")\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    #conv_base.summary()\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in conv_base.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "# making the FC layers of the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(nodes, activation='relu'))\n",
    "model.add(layers.Dropout(drop_out))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#model.summary()\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=learning_rate), metrics=['acc'])\n",
    "\n",
    "# defining k-fold cross validation test harness\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = k_fold, shuffle = True, random_state = np.random.seed(7))\n",
    "cvscores1 = []\n",
    "cvscores2 = []\n",
    "i = 1\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    # data augmentation\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # training the model\n",
    "\n",
    "    print('fold %d:' % (i))\n",
    "    batch_size = batch_size\n",
    "    H = model.fit_generator(\n",
    "        train_datagen.flow(X[train], y[train], batch_size = batch_size),\n",
    "        steps_per_epoch=len(X[train]) // batch_size,\n",
    "        epochs=epoch_size,\n",
    "        validation_data=(X[test], y[test]),\n",
    "        validation_steps=len(X[test]) // batch_size)\n",
    "\n",
    "    # computing the accuracy metric for this CV fold\n",
    "    \n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores1.append(scores[1] * 100)\n",
    "    \n",
    "    # computing the AUC metric for this CV fold\n",
    "\n",
    "    preds = model.predict(X[test])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y[test], preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"%s: %.2f%%\" % ('auc', roc_auc*100));\n",
    "    cvscores2.append(roc_auc*100)\n",
    "    i = i + 1\n",
    "    print('');\n",
    "\n",
    "print(\"tot_acc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores1), np.std(cvscores1)));\n",
    "print(\"tot_auc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores2)));\n",
    "\n",
    "# saving the model\n",
    "\n",
    "model.save_weights('model_weights_lung_pro_cv_image.h5')\n",
    "model.save('model_lung_pro_cv_image.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_test: (21, 224, 224, 3)\n",
      "shape of y_test: (21,)\n",
      "21/21 [==============================] - 1s 28ms/step\n",
      "\n",
      "Predicted labels: [1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1]\n",
      "\n",
      "True labels: [0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "\n",
      "[False  True False  True  True  True  True False  True False  True  True\n",
      "  True False False  True False False False False False]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this cell to test the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# loading the model\n",
    "\n",
    "#model = load_model('model_lung_pro_cv_image.h5')\n",
    "#model.summary()\n",
    "\n",
    "# getting the images for testing\n",
    "\n",
    "file_list2 = os.listdir(test_dir)\n",
    "test_imgs = [test_dir + \"/\" + \"{}\".format(i) for i in file_list2]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "X_test = []\n",
    "for image in test_imgs:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = (X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test))\n",
    "#X_test = X_test/255.0\n",
    "print(\"shape of X_test:\", X_test.shape)\n",
    "\n",
    "df = pandas.read_csv(csvTest)\n",
    "#print('shape of the dataframe:', df.shape)\n",
    "#print(df.head(2))\n",
    "\n",
    "# getting the true labels for testing\n",
    "\n",
    "na = df.loc[:,'File']\n",
    "la = df.loc[:,'Progression']\n",
    "na = np.array(na)\n",
    "la = np.array(la)\n",
    "I = np.argsort(na)\n",
    "na = na[I]\n",
    "la = la[I]\n",
    "y_test = la\n",
    "#sns.set(rc={'figure.figsize':(5,4)})\n",
    "#sns.countplot (y_test)\n",
    "#plt.title(\"Labels\")\n",
    "print (\"shape of y_test:\", y_test.shape)\n",
    "\n",
    "# model prediction\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "predictions_test = preds_test_t [:, 0]\n",
    "print(\"\")\n",
    "print(\"Predicted labels:\", predictions_test)\n",
    "print(\"\")\n",
    "print(\"True labels:\", y_test)\n",
    "print(\"\")\n",
    "com = np.isclose(predictions_test, y_test.T)\n",
    "print (com)\n",
    "#true_prediction_number = 1 * (com == 'True')\n",
    "#print(true_prediction_number)\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
