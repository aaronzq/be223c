{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import os\n",
    "# to run on GPU, comment the following tow lines \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pylab\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from util3 import read_data # with image\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# train\n",
    "\n",
    "csvPath = 'OLD2/Master1.csv'\n",
    "imagePath = '/home/maalidoost/OLD2/Seg1'\n",
    "\n",
    "inputSize = (224,224)\n",
    "k_fold = 2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-6\n",
    "epoch_size = 1\n",
    "drop_out = 0.5 # after fc layer\n",
    "\n",
    "# test\n",
    "\n",
    "test_dir = '/home/maalidoost/Seg2'\n",
    "csvTest = 'Master2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: 105 positive,59 negatve.\n",
      "Split dataset according to images. Training : 978 images; Validation: 6 images.\n",
      "\n",
      "using images\n",
      "\n",
      "train_images: (978, 224, 224, 3)\n",
      "train_labels: (978,)\n",
      "\n",
      "getting the model\n",
      "\n",
      "fold 1:\n",
      "Epoch 1/1\n",
      "15/15 [==============================] - 9s 609ms/step - loss: 0.8588 - acc: 0.4229 - val_loss: 0.6729 - val_acc: 0.6074\n",
      "acc: 60.74%\n",
      "auc: 48.36%\n",
      "\n",
      "fold 2:\n",
      "Epoch 1/1\n",
      "15/15 [==============================] - 8s 549ms/step - loss: 0.7223 - acc: 0.5917 - val_loss: 0.6710 - val_acc: 0.6380\n",
      "acc: 63.80%\n",
      "auc: 51.35%\n",
      "\n",
      "tot_acc_avg: 62.27% (+/- 1.53%)\n",
      "tot_auc_avg: 49.85% (+/- 1.50%)\n"
     ]
    }
   ],
   "source": [
    "# preparing the data to train\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "train_img,train_label,val_img,val_label = read_data(csvPath,\n",
    "        imagePath, inputSize, 0.00001, split_by_id=False, normalize=True, crop_image=True)\n",
    "train_img = np.stack( (train_img[:,:,:,0],)*3, axis=-1 )\n",
    "X = train_img\n",
    "y = train_label\n",
    "\n",
    "print(\"\")\n",
    "print(\"using images\")\n",
    "print(\"\")\n",
    "print(\"train_images:\", train_img.shape)\n",
    "print(\"train_labels:\", train_label.shape)\n",
    "#print(\"validation_images:\", val_img.shape)\n",
    "#print(\"validation_label:\", val_label.shape)\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "print(\"\")\n",
    "print(\"getting the model\")\n",
    "print(\"\")\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    #conv_base.summary()\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in conv_base.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "# making the FC layers of the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(drop_out))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=learning_rate), metrics=['acc'])\n",
    "\n",
    "# defining k-fold cross validation test harness\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = k_fold, shuffle = True, random_state = np.random.seed(7))\n",
    "cvscores1 = []\n",
    "cvscores2 = []\n",
    "i = 1\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "# data augmentation\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# training the model\n",
    "\n",
    "    print('fold %d:' % (i))\n",
    "    batch_size = batch_size\n",
    "    H = model.fit_generator(\n",
    "        train_datagen.flow(X[train], y[train], batch_size = batch_size),\n",
    "        steps_per_epoch=len(X[train]) // batch_size,\n",
    "        epochs=epoch_size,\n",
    "        validation_data=(X[test], y[test]),\n",
    "        validation_steps=len(X[test]) // batch_size)\n",
    "\n",
    "# computing the accuracy metric for this CV fold\n",
    "    \n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores1.append(scores[1] * 100)\n",
    "    \n",
    "# computing the AUC metric for this CV fold\n",
    "\n",
    "    preds = model.predict(X[test])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y[test], preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"%s: %.2f%%\" % ('auc', roc_auc*100));\n",
    "    cvscores2.append(roc_auc*100)\n",
    "    i = i + 1\n",
    "    print('');\n",
    "\n",
    "print(\"tot_acc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores1), np.std(cvscores1)));\n",
    "print(\"tot_auc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores2)));\n",
    "\n",
    "# saving the model\n",
    "\n",
    "model.save_weights('model_weights_lung_pro_cv_image.h5')\n",
    "model.save('model_lung_pro_cv_image.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/maalidoost/Seg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec26a882bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# getting X and y for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfile_list2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(\"No. of test images = \", len(test_imgs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/maalidoost/Seg2'"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "# loading the model\n",
    "\n",
    "#model = load_model('model_lung_pro.h5')\n",
    "#model.summary()\n",
    "\n",
    "# getting X and y for testing\n",
    "\n",
    "file_list2 = os.listdir(test_dir)\n",
    "test_imgs = [test_dir + \"/\" + \"{}\".format(i) for i in file_list2]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "\n",
    "X_test = []\n",
    "IMG_SIZE = 224\n",
    "for image in test_imgs:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test/255.0\n",
    "print(\"shape of X_test:\", X_test.shape)\n",
    "\n",
    "df = pandas.read_csv(csvTest)\n",
    "#print('shape of the dataframe:', df.shape)\n",
    "#print(df.head(2))\n",
    "\n",
    "na = df.loc[:,'File']\n",
    "la = df.loc[:,'Progression']\n",
    "na = np.array(na)\n",
    "la = np.array(la)\n",
    "I = np.argsort(na)\n",
    "na = na[I]\n",
    "la = la[I]\n",
    "y_test = la\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.countplot (y_test)\n",
    "plt.title(\"Labels\")\n",
    "print (\"shape of y_test:\", y_test.shape)\n",
    "\n",
    "# model prediction\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "predictions_test = preds_test_t [:, 0]\n",
    "print(\"\")\n",
    "\n",
    "print(\"Predicted labels:\", predictions_test)\n",
    "print(\"\")\n",
    "print(\"True labels:\", y_test)\n",
    "print(\"\")\n",
    "\n",
    "com = np.isclose(predictions_test, y_test.T)\n",
    "print (com)\n",
    "\n",
    "#true_prediction_number = 1 * (com == 'True')\n",
    "#print(true_prediction_number)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
