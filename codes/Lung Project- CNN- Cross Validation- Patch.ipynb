{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import os\n",
    "# to run on GPU, comment the following tow lines \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pylab\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from util5 import read_data_random_view # patch\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# input shape for the VGG16 (it sould be the same as patch size)\n",
    "\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "# train\n",
    "\n",
    "csvPath = 'OLD2/Master2M.csv'\n",
    "imagePath = '/home/maalidoost/OLD2/Seg2M'\n",
    "patchPath = '/home/maalidoost/OLD2/Seg2Mask'\n",
    "\n",
    "inputSize = (224, 224)\n",
    "patchSize = (64, 64)\n",
    "split_ratio = 0.2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-6\n",
    "epoch_size = 2\n",
    "nodes = 512 # number of nodes for the fc layer\n",
    "drop_out = 0.5 # after the fc layer\n",
    "k_fold = 2\n",
    "\n",
    "# test\n",
    "\n",
    "test_dir = '/home/maalidoost/Seg2'\n",
    "csvTest = 'Master2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: 16 positive,15 negatve.\n",
      "Images loaded: 31; Masks loaded: 31\n",
      "Random view sampling patch input training data preparation:\n",
      "\n",
      "using patches\n",
      "\n",
      "fold 1, patch size: (2025, 64, 64, 3)\n",
      "fold 1, label size: (2,)\n",
      "fold 1, val_patch size: (2160, 64, 64, 3)\n",
      "fold 1, val_label size: (2,)\n",
      "\n",
      "fold 2, patch size: (2160, 64, 64, 3)\n",
      "fold 2, label size: (2,)\n",
      "fold 2, val_patch size: (2025, 64, 64, 3)\n",
      "fold 2, val_label size: (2,)\n",
      "\n",
      "getting the model\n",
      "\n",
      "fold 1:\n",
      "Epoch 1/2\n",
      "63/63 [==============================] - 6s 96ms/step - loss: 0.7709 - acc: 0.5134 - val_loss: 0.7158 - val_acc: 0.4560\n",
      "Epoch 2/2\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 0.7525 - acc: 0.5202 - val_loss: 0.7017 - val_acc: 0.4903\n",
      "acc: 49.03%\n",
      "auc: 50.33%\n",
      "\n",
      "fold 2:\n",
      "Epoch 1/2\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.7728 - acc: 0.4911"
     ]
    }
   ],
   "source": [
    "# preparing the data to train\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "train_patch_kfold, train_label_kfold, val_patch_kfold, val_label_kfold = \\\n",
    "read_data_random_view(csvPath, imagePath, patchPath, inputSize, patchSize, split_ratio, kfold= k_fold, outchannels=3)\n",
    "\n",
    "print(\"\")\n",
    "print(\"using patches\")\n",
    "print(\"\")\n",
    "\n",
    "for i in range(k_fold):\n",
    "    print ('fold %d, patch size:' % (i+1), train_patch_kfold[i].shape)\n",
    "    print ('fold %d, label size:' % (i+1), train_label_kfold.shape)\n",
    "    print ('fold %d, val_patch size:' % (i+1), val_patch_kfold[i].shape)\n",
    "    print ('fold %d, val_label size:' % (i+1), val_label_kfold.shape)\n",
    "    print(\"\")\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "print(\"getting the model\")\n",
    "print(\"\")\n",
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
    "#conv_base.summary()\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in conv_base.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "# making the FC layers of the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(nodes, activation='relu'))\n",
    "model.add(layers.Dropout(drop_out))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=learning_rate), metrics=['acc'])\n",
    "\n",
    "# defining k-fold cross validation test harness\n",
    "\n",
    "cvscores1 = []\n",
    "cvscores2 = []\n",
    "i = 1\n",
    "for j in range(k_fold):\n",
    "    X = train_patch_kfold[j]\n",
    "    y = train_label_kfold[j]\n",
    "    X_t = val_patch_kfold[j]\n",
    "    y_t = val_label_kfold[j]\n",
    "    \n",
    "    # data augmentation\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # training the model\n",
    "\n",
    "    print('fold %d:' % (i))\n",
    "    H = model.fit_generator(\n",
    "        train_datagen.flow(X, y, batch_size = batch_size),\n",
    "        steps_per_epoch=len(X) // batch_size,\n",
    "        epochs=epoch_size,\n",
    "        validation_data=(X_t, y_t),\n",
    "        validation_steps=len(X_t) // batch_size)\n",
    "\n",
    "    # computing the accuracy metric for this CV fold\n",
    "    \n",
    "    scores = model.evaluate(X_t, y_t, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores1.append(scores[1] * 100)\n",
    "    \n",
    "    # computing the AUC metric for this CV fold\n",
    "\n",
    "    preds = model.predict(X_t)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_t, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"%s: %.2f%%\" % ('auc', roc_auc*100));\n",
    "    cvscores2.append(roc_auc*100)\n",
    "    i = i + 1\n",
    "    print('');\n",
    "\n",
    "print(\"tot_acc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores1), np.std(cvscores1)));\n",
    "print(\"tot_auc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores2)));\n",
    "\n",
    "# saving the model\n",
    "\n",
    "model.save_weights('model_weights_lung_pro_cv_patch.h5')\n",
    "model.save('model_lung_pro5_cv_patch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/maalidoost/Seg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec26a882bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# getting X and y for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfile_list2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(\"No. of test images = \", len(test_imgs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/maalidoost/Seg2'"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "# loading the model\n",
    "\n",
    "#model = load_model('model_lung_pro.h5')\n",
    "#model.summary()\n",
    "\n",
    "# getting X and y for testing\n",
    "\n",
    "file_list2 = os.listdir(test_dir)\n",
    "test_imgs = [test_dir + \"/\" + \"{}\".format(i) for i in file_list2]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "\n",
    "X_test = []\n",
    "IMG_SIZE = 224\n",
    "for image in test_imgs:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test/255.0\n",
    "print(\"shape of X_test:\", X_test.shape)\n",
    "\n",
    "df = pandas.read_csv(csvTest)\n",
    "#print('shape of the dataframe:', df.shape)\n",
    "#print(df.head(2))\n",
    "\n",
    "na = df.loc[:,'File']\n",
    "la = df.loc[:,'Progression']\n",
    "na = np.array(na)\n",
    "la = np.array(la)\n",
    "I = np.argsort(na)\n",
    "na = na[I]\n",
    "la = la[I]\n",
    "y_test = la\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.countplot (y_test)\n",
    "plt.title(\"Labels\")\n",
    "print (\"shape of y_test:\", y_test.shape)\n",
    "\n",
    "# model prediction\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "predictions_test = preds_test_t [:, 0]\n",
    "print(\"\")\n",
    "\n",
    "print(\"Predicted labels:\", predictions_test)\n",
    "print(\"\")\n",
    "print(\"True labels:\", y_test)\n",
    "print(\"\")\n",
    "\n",
    "com = np.isclose(predictions_test, y_test.T)\n",
    "print (com)\n",
    "\n",
    "#true_prediction_number = 1 * (com == 'True')\n",
    "#print(true_prediction_number)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
