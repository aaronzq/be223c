{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this code gets only the patches to trian the pre-trained model using the cross validation technique\n",
    "\n",
    "# use this cell to import all necessary libraries\n",
    "\n",
    "import os\n",
    "# to run on GPU, comment the following two lines \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pylab\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from util import read_data_random_view, read_patch_test, read_patch_rvs_test, gray2RGB\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to get all of the input parameters and paths to train and tune\n",
    "\n",
    "# input shape for the pretrained model(it sould be the same as patch size)\n",
    "\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "# input parameters and paths for training\n",
    "\n",
    "csvPath = '/home/mohammadali/Downloads/Run/Train.csv'\n",
    "imagePath = '/home/mohammadali/Downloads/Run/Train-Seg-Man'\n",
    "patchPath = '/home/mohammadali/Downloads/Run/Train-Patch'\n",
    "inputSize = (224, 224)\n",
    "patchSize = (64, 64)\n",
    "split_ratio = 0.2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-6\n",
    "epoch_size = 2\n",
    "nodes = 512 # number of nodes for the fc layer\n",
    "drop_out = 0.1 # the layer after the fc layer\n",
    "k_fold = 2\n",
    "\n",
    "# input parameters and paths for testing\n",
    "\n",
    "test_dir = '/home/mohammadali/Downloads/Run/Test-Seg-Man'\n",
    "test_dir_patch = '/home/mohammadali/Downloads/Run/Test-Patch'\n",
    "csvTest = '/home/mohammadali/Downloads/Run/Test.csv'\n",
    "IMG_SIZE = 224\n",
    "Patch_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: 50 positive,45 negatve.\n",
      "Images loaded: 95; Masks loaded: 95\n",
      "\n",
      "using patches\n",
      "\n",
      "fold 1, patch size: (6345, 64, 64, 3)\n",
      "fold 1, label size: (6345,)\n",
      "fold 1, val_patch size: (6480, 64, 64, 3)\n",
      "fold 1, val_label size: (6480,)\n",
      "\n",
      "fold 2, patch size: (6480, 64, 64, 3)\n",
      "fold 2, label size: (6480,)\n",
      "fold 2, val_patch size: (6345, 64, 64, 3)\n",
      "fold 2, val_label size: (6345,)\n",
      "\n",
      "getting the model\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "fold 1:\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "198/198 [==============================] - 9s 48ms/step - loss: 0.7249 - acc: 0.5908 - val_loss: 0.7389 - val_acc: 0.4231\n",
      "Epoch 2/2\n",
      "198/198 [==============================] - 8s 40ms/step - loss: 0.6193 - acc: 0.6756 - val_loss: 0.7377 - val_acc: 0.4668\n",
      "acc: 46.68%\n",
      "auc: 52.33%\n",
      "\n",
      "fold 2:\n",
      "Epoch 1/2\n",
      "202/202 [==============================] - 8s 41ms/step - loss: 0.6487 - acc: 0.6160 - val_loss: 0.6452 - val_acc: 0.5964\n",
      "Epoch 2/2\n",
      "202/202 [==============================] - 8s 40ms/step - loss: 0.5761 - acc: 0.6946 - val_loss: 0.6691 - val_acc: 0.6085\n",
      "acc: 60.85%\n",
      "auc: 76.23%\n",
      "\n",
      "tot_acc_avg: 53.77% (+/- 7.08%)\n",
      "tot_auc_avg: 64.28% (+/- 11.95%)\n"
     ]
    }
   ],
   "source": [
    "# use this cell to train the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# preparing the data to train\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "train_patch_kfold, train_label_kfold, val_patch_kfold, val_label_kfold = \\\n",
    "read_data_random_view(csvPath, imagePath, patchPath, inputSize, patchSize, split_ratio, kfold= k_fold, outchannels=3)\n",
    "\n",
    "print(\"\")\n",
    "print(\"using patches\")\n",
    "print(\"\")\n",
    "for i in range(k_fold):\n",
    "    print ('fold %d, patch size:' % (i+1), train_patch_kfold[i].shape)\n",
    "    print ('fold %d, label size:' % (i+1), train_label_kfold[i].shape)\n",
    "    print ('fold %d, val_patch size:' % (i+1), val_patch_kfold[i].shape)\n",
    "    print ('fold %d, val_label size:' % (i+1), val_label_kfold[i].shape)\n",
    "    print(\"\")\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "print(\"getting the model\")\n",
    "print(\"\")\n",
    "conv_base = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
    "#conv_base.summary()\n",
    "\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in conv_base.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "# making the FC layers of the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(nodes, activation='relu'))\n",
    "model.add(layers.Dropout(drop_out))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#model.summary()\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=learning_rate), metrics=['acc'])\n",
    "\n",
    "# defining k-fold cross validation test harness\n",
    "\n",
    "cvscores1 = []\n",
    "cvscores2 = []\n",
    "i = 1\n",
    "for j in range(k_fold):\n",
    "    X = train_patch_kfold[j]\n",
    "    y = train_label_kfold[j]\n",
    "    X_t = val_patch_kfold[j]\n",
    "    y_t = val_label_kfold[j]\n",
    "    \n",
    "    # data augmentation\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # training the model\n",
    "\n",
    "    print('fold %d:' % (i))\n",
    "    H = model.fit_generator(\n",
    "        train_datagen.flow(X, y, batch_size = batch_size),\n",
    "        steps_per_epoch=len(X) // batch_size,\n",
    "        epochs=epoch_size,\n",
    "        validation_data=(X_t, y_t),\n",
    "        validation_steps=len(X_t) // batch_size)\n",
    "\n",
    "    # computing the accuracy metric for this CV fold\n",
    "    \n",
    "    scores = model.evaluate(X_t, y_t, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores1.append(scores[1] * 100)\n",
    "    \n",
    "    # computing the AUC metric for this CV fold\n",
    "\n",
    "    preds = model.predict(X_t)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_t, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"%s: %.2f%%\" % ('auc', roc_auc*100));\n",
    "    cvscores2.append(roc_auc*100)\n",
    "    i = i + 1\n",
    "    print('');\n",
    "\n",
    "print(\"tot_acc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores1), np.std(cvscores1)));\n",
    "print(\"tot_auc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores2)));\n",
    "\n",
    "# saving the model\n",
    "\n",
    "model.save_weights('model_weights_lung_pro_cv_patch.h5')\n",
    "model.save('model_lung_pro_cv_patch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_test: (21, 224, 224)\n",
      "shape of X_testing1: (21, 224, 224, 3)\n",
      "shape of X_test_patch: (21, 64, 64)\n",
      "shape of X_testing2: (21, 64, 64, 3)\n",
      "shape of y_test: (21,)\n",
      "\n",
      "21/21 [==============================] - 0s 8ms/step\n",
      "\n",
      "Predicted labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "True labels: [0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "\n",
      "[ True  True  True False False False  True  True  True False False False\n",
      " False False False False False False  True  True  True]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this cell to test the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# loading the model\n",
    "\n",
    "model = load_model('model_lung_pro_cv_patch.h5')\n",
    "#model.summary()\n",
    "\n",
    "# getting the images for testing\n",
    "\n",
    "file_list2 = os.listdir(test_dir)\n",
    "test_imgs = [test_dir + \"/\" + \"{}\".format(i) for i in file_list2]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "    \n",
    "X_test = []\n",
    "for image in test_imgs:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "X_test = np.array(X_test)\n",
    "X_test = (X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test))\n",
    "#X_test = X_test/255.0\n",
    "print(\"shape of X_test:\", X_test.shape)\n",
    "\n",
    "X_testing1 = []\n",
    "for m in range (len(X_test)):\n",
    "    X_testt = X_test[m]\n",
    "    X_testing1.append(gray2RGB(X_testt))\n",
    "X_testing1 = np.array(X_testing1)\n",
    "print(\"shape of X_testing1:\", X_testing1.shape)\n",
    "\n",
    "# getting the patches for testing\n",
    "\n",
    "file_list3 = os.listdir(test_dir_patch)\n",
    "test_imgs_patch = [test_dir_patch + \"/\" + \"{}\".format(i) for i in file_list3]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "X_test_patch = []\n",
    "for image in test_imgs_patch:\n",
    "    X_test_patch.append(cv2.resize(cv2.imread(image, cv2.IMREAD_GRAYSCALE), (Patch_SIZE, Patch_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "X_test_patch = np.array(X_test_patch)\n",
    "print(\"shape of X_test_patch:\", X_test_patch.shape)\n",
    "\n",
    "X_test_final = []\n",
    "for h in range (len(X_test_patch)):\n",
    "    X_test_final.append(read_patch_test(X_test[h], X_test_patch[h], patch_size = (Patch_SIZE, Patch_SIZE)))\n",
    "X_test_final = np.array(X_test_final)\n",
    "\n",
    "X_testing2 = []\n",
    "for m in range (len(X_test_final)):\n",
    "    X_testt = X_test_final[m]\n",
    "    X_testing2.append(gray2RGB(X_testt))\n",
    "X_testing2 = np.array(X_testing2)\n",
    "print(\"shape of X_testing2:\", X_testing2.shape)\n",
    "\n",
    "# getting the true labels for testing\n",
    "\n",
    "df = pandas.read_csv(csvTest)\n",
    "#print('shape of the dataframe:', df.shape)\n",
    "#print(df.head(2))\n",
    "na = df.loc[:,'File']\n",
    "la = df.loc[:,'Progression']\n",
    "na = np.array(na)\n",
    "la = np.array(la)\n",
    "I = np.argsort(na)\n",
    "na = na[I]\n",
    "la = la[I]\n",
    "y_test = la\n",
    "#sns.set(rc={'figure.figsize':(5,4)})\n",
    "#sns.countplot (y_test)\n",
    "#plt.title(\"Labels\")\n",
    "print (\"shape of y_test:\", y_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "# model prediction\n",
    "\n",
    "preds_test = model.predict(X_testing2, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "predictions_test = preds_test_t [:, 0]\n",
    "print(\"\")\n",
    "print(\"Predicted labels:\", predictions_test)\n",
    "print(\"\")\n",
    "print(\"True labels:\", y_test)\n",
    "print(\"\")\n",
    "com = np.isclose(predictions_test, y_test.T)\n",
    "print (com)\n",
    "#true_prediction_number = 1 * (com == 'True')\n",
    "#print(true_prediction_number)\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
