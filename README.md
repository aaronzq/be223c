## To run with Docker
- On the AWS server:
```bash
$ docker run project_lung
```
This will start a Docker container running the web server listening on port 8085.
Because the Docker container has its private IP, you will need to look up the IP and proxy into the server to reach it.
- Find the container's ID by running:
```bash
$ docker ps
```
- Then get the container's private IP with:
```bash
$ docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' CONTAINER_ID
```
Reference: https://stackoverflow.com/a/20686101/3704042

## Directories and file descriptions

- [/data](https://github.com/fivebillionmph/be223c/tree/master/data)
  - This is where all the variable or generated data is kept.  This includes the classification models, miniVGG model, automatic lung segmentation model, model test results and the lung images (original images, lesion segmentations, patches, etc).
  - This directory is not as organized, it has unused models and images because data was swapped out and interchanged.
  - It is gitignored, but the data is packaged in the zip file submitted to CCLE.

- /data/miniVGG.h5
  - The miniVGG hash model HDF5 file

- /data/segs2/patches-training
  - Directory of patches that are hashed and checked against for the content based retrieval image similarity

- /data/lesion_classification.model
  - HDF5 file for the UNET encoder based whole image lesion classification model (model 1)
  - This was generated by [/src/mod/classify_lesion.py](https://github.com/fivebillionmph/be223c/blob/master/src/mod/classify_lesion.py)

- /data/model_lung_pro_cv_patch.h5
  - HDF5 file for the VGG16 based patch classification model (model 2)
  - This was generated by [/src2/mohammad/lung_pa_cv.py](https://github.com/fivebillionmph/be223c/blob/master/src2/mohammad/lung_pa_cv.py)

- /data/model_lung_pro_cv_image1.h5
  - HDF5 file for the VGG16 based whole image classification model (model 3)
  - This was generated by [/src2/mohammad/lung_im_cv.py](https://github.com/fivebillionmph/be223c/blob/master/src2/mohammad/lung_im_cv.py)

- /data/lung_seg.mode
  - HDF5 file for the lung segmentation model
  - This was generated by [/src/mod/seg_lung.py](https://github.com/fivebillionmph/be223c/blob/master/src/mod/seg_lung.py)

- /data/Train.csv
  - The training set images and their labels

- /data/Test.csv
  - The test set images and their labels

- /data/test-model\*
  - The test results files for the 3 models which ROC, AUC, etc...

- [/scripts](https://github.com/fivebillionmph/be223c/tree/master/scripts)
  - Simple scripts for starting the web server and getting the installed Python modules

- [/src](https://github.com/fivebillionmph/be223c/tree/master/src)
  - Python scripts for running the server, segmenting, testing models, training the miniVGG, etc
  - The description of each script and it's purpose is in the file's main function

- [/src/server.py](https://github.com/fivebillionmph/be223c/blob/master/src/server.py)
  - The main Flask server script

- [/src/mod](https://github.com/fivebillionmph/be223c/tree/master/src/mod)
  - Shared modules used by scripts in /src.

- [/src2](https://github.com/fivebillionmph/be223c/tree/master/src2)
  - Other scripts for generating models or segmenting

- [/src2/amy](https://github.com/fivebillionmph/be223c/tree/master/src2/amy)
  - Scripts written by Amy for preprocessing and segmenting the lung images

- [/src2/mohammad](https://github.com/fivebillionmph/be223c/tree/master/src2/mohammad)
  - Scripts for generating the VGG16 based classifier models

- [/web](https://github.com/fivebillionmph/be223c/tree/master/web)
  - HTML templates and static CSS, JS and images

## Project overview
This project attempts to predict if a lung cancer patient will respond to immunotherapy treatment. Lung CT scans were taken before and after treatment with anti-PD1 immunotherapy.

Three deep learning models were trained on the pre-treatment images to classify if the disease will pregress or not: A encoder based model which classifies against the entire image, a VGG16 based model which classifies based on the selected patch and a VGG16 based model which classifies on the whole image.

A content based retrieval based on miniVGG and image similarity hashing was also trained so similar lesions can be returned.

An automatic lung segmentation model was also created so that users do not need to segment the lungs out of surrounding tissue themselves.
