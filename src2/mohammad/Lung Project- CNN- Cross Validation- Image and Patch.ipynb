{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# this code gets both the images and patches to trian the pre-trained model using the cross validation technique\n",
    "\n",
    "# use this cell to import all necessary libraries\n",
    "\n",
    "import os\n",
    "# to run on GPU, comment the following tow lines \n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import pylab\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from util import read_data_dual_input, read_patch_test, read_patch_rvs_test, gray2RGB\n",
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to get all of the input parameters and paths to train and tune\n",
    "\n",
    "# input shapes for the pretrained models(input_1 and input_2 are the image and patch inputs respectively)\n",
    "\n",
    "input_1 = (224, 224, 3)\n",
    "input_2 = (64, 64, 3)\n",
    "\n",
    "# input parameters and paths for training\n",
    "\n",
    "csvPath = '/home/mohammadali/Downloads/Run/Train.csv'\n",
    "imagePath = '/home/mohammadali/Downloads/Run/Train-Seg-Man'\n",
    "patchPath = '/home/mohammadali/Downloads/Run/Train-Patch'\n",
    "inputSize = (224,224)\n",
    "patchSize = (64, 64)\n",
    "split_ratio = 0.2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-6\n",
    "epoch_size = 2\n",
    "nodes = 1024 # number of nodes for the fc layer\n",
    "drop_out = 0.5 # the layer after the fc layer\n",
    "k_fold = 2\n",
    "\n",
    "# input parameters and paths for testing\n",
    "\n",
    "test_dir = '/home/mohammadali/Downloads/Run/Test-Seg-Man'\n",
    "test_dir_patch = '/home/mohammadali/Downloads/Run/Test-Patch'\n",
    "csvTest = '/home/mohammadali/Downloads/Run/Test.csv'\n",
    "IMG_SIZE = 224\n",
    "Patch_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: 50 positive,45 negatve.\n",
      "Images loaded: 95; Masks loaded: 95\n",
      "\n",
      "multiple inputs model\n",
      "\n",
      "fold 1, image size: (282, 224, 224, 3)\n",
      "fold 1, patch size: (282, 64, 64, 3)\n",
      "fold 1, label size: (282,)\n",
      "fold 1, val_image size: (288, 224, 224, 3)\n",
      "fold 1, val_patch size: (288, 64, 64, 3)\n",
      "fold 1, val_label size: (288,)\n",
      "\n",
      "fold 2, image size: (288, 224, 224, 3)\n",
      "fold 2, patch size: (288, 64, 64, 3)\n",
      "fold 2, label size: (288,)\n",
      "fold 2, val_image size: (282, 224, 224, 3)\n",
      "fold 2, val_patch size: (282, 64, 64, 3)\n",
      "fold 2, val_label size: (282,)\n",
      "\n",
      "\n",
      "making the model for the first input\n",
      "\n",
      "making the model for the second input\n",
      "\n",
      "fold 1:\n",
      "WARNING:tensorflow:From /home/mohammadali/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.7304 - acc: 0.4844 - val_loss: 0.7157 - val_acc: 0.4688\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.7426 - acc: 0.4976 - val_loss: 0.7453 - val_acc: 0.4097\n",
      "acc: 40.97%\n",
      "auc: 62.90%\n",
      "\n",
      "fold 2:\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 3s 383ms/step - loss: 0.7728 - acc: 0.4965 - val_loss: 0.6651 - val_acc: 0.6064\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.7397 - acc: 0.5035 - val_loss: 0.6968 - val_acc: 0.5177\n",
      "acc: 51.77%\n",
      "auc: 67.75%\n",
      "\n",
      "tot_acc_avg: 46.37% (+/- 5.40%)\n",
      "tot_auc_avg: 65.32% (+/- 2.42%)\n"
     ]
    }
   ],
   "source": [
    "# use this cell to train the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# preparing the data to train\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "train_images, train_patches, train_labels, val_images, val_patches, val_labels = \\\n",
    "read_data_dual_input(csvPath, imagePath, patchPath, inputSize, patchSize, split_ratio,\n",
    "                     aug_rotate = 6, kfold = k_fold, outchannels = 3)\n",
    "print(\"\")\n",
    "print(\"multiple inputs model\")\n",
    "print(\"\")\n",
    "for i in range(k_fold):\n",
    "    print ('fold %d, image size:' % (i+1), train_images[i].shape)\n",
    "    print ('fold %d, patch size:' % (i+1), train_patches[i].shape)\n",
    "    print ('fold %d, label size:' % (i+1), train_labels[i].shape)\n",
    "    print ('fold %d, val_image size:' % (i+1), val_images[i].shape)\n",
    "    print ('fold %d, val_patch size:' % (i+1), val_patches[i].shape)\n",
    "    print ('fold %d, val_label size:' % (i+1), val_labels[i].shape)\n",
    "    print(\"\")\n",
    "print(\"\")\n",
    "print(\"making the model for the first input\")\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "conv_base_1 = VGG16(weights = 'imagenet', include_top = False, input_shape = input_1)\n",
    "#conv_base_1.summary()\n",
    "\n",
    "for layer in conv_base_1.layers:\n",
    "    layer.name = layer.name + str(\"_1\")\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "#layer_dict = dict([(layer.name, layer) for layer in conv_base.layers])\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "#lay = layer_dict['block5_pool'].output\n",
    "#print (lay)\n",
    "\n",
    "for layer in conv_base_1.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "\n",
    "#for layer in conv_base_1.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "inp_1 = layers.Input(shape = input_1)\n",
    "conv_base_out_1 = conv_base_1(inp_1)\n",
    "flat_1 = layers.Flatten()(conv_base_out_1)\n",
    "#print(flat_1)\n",
    "print(\"\")\n",
    "print(\"making the model for the second input\")\n",
    "print(\"\")\n",
    "\n",
    "# using the pretrained model for training\n",
    "\n",
    "#conv_base_2 = VGG16(weights = 'imagenet', include_top = False, input_shape = input_2)\n",
    "conv_base_2 = VGG19(weights = 'imagenet', include_top = False, input_shape = input_2)\n",
    "#conv_base_2 = ResNet50(weights = 'imagenet', include_top = False, input_shape = input_2)\n",
    "\n",
    "for layer in conv_base_2.layers:\n",
    "    layer.name = layer.name + str(\"_2\")\n",
    "#conv_base_2.summary()\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "#layer_dict = dict([(layer.name, layer) for layer in conv_base.layers])\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "#lay = layer_dict['block5_pool'].output\n",
    "#print (lay)\n",
    "\n",
    "for layer in conv_base_2.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "\n",
    "#for layer in conv_base_2.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "inp_2 = layers.Input(shape = input_2)\n",
    "conv_base_out_2 = conv_base_2(inp_2)\n",
    "flat_2 = layers.Flatten()(conv_base_out_2)\n",
    "#print(flat_2)\n",
    "\n",
    "# making the FC layers of the model\n",
    "\n",
    "concat = layers.merge.concatenate([flat_1, flat_2])\n",
    "dense1 = layers.Dense(nodes, activation = 'relu')(concat)\n",
    "dense1 = layers.Dropout(drop_out)(dense1)\n",
    "output = layers.Dense(1, activation= 'sigmoid')(dense1)\n",
    "\n",
    "# creating the model with two inputs\n",
    "\n",
    "model = models.Model(inputs = [inp_1, inp_2], outputs = output)\n",
    "#print(model.summary())\n",
    "\n",
    "# plotting the model graph\n",
    "\n",
    "#plot_model(model, to_file='multiple_inputs.png')\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=learning_rate), metrics=['acc'])\n",
    "\n",
    "# defining k-fold cross validation test harness\n",
    "\n",
    "cvscores1 = []\n",
    "cvscores2 = []\n",
    "i = 1\n",
    "for j in range(k_fold):\n",
    "    X1 = train_images[j]\n",
    "    X2 = train_patches[j]\n",
    "    y = train_labels[j]\n",
    "    X1_t = val_images[j]\n",
    "    X2_t = val_patches[j]\n",
    "    y_t = val_labels[j]\n",
    "\n",
    "    # data augmentation\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    #val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # training the model\n",
    "\n",
    "    print('fold %d:' % (i))\n",
    "    H = model.fit_generator(\n",
    "        train_datagen.flow([X1, X2], y, batch_size = batch_size),\n",
    "        steps_per_epoch= len(X1) // batch_size,\n",
    "        epochs = epoch_size,\n",
    "        validation_data = ([X1_t, X2_t], y_t),\n",
    "        validation_steps = len(X1_t) // batch_size)\n",
    "\n",
    "    # computing the accuracy metric for this CV fold\n",
    "    \n",
    "    scores = model.evaluate([X1_t, X2_t], y_t, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores1.append(scores[1] * 100)\n",
    "    \n",
    "    # computing the AUC metric for this CV fold\n",
    "\n",
    "    preds = model.predict([X1_t, X2_t])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_t, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"%s: %.2f%%\" % ('auc', roc_auc*100));\n",
    "    cvscores2.append(roc_auc*100)\n",
    "    i = i + 1\n",
    "    print('');\n",
    "\n",
    "print(\"tot_acc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores1), np.std(cvscores1)));\n",
    "print(\"tot_auc_avg: %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores2)));\n",
    "\n",
    "# saving the model\n",
    "\n",
    "model.save_weights('model_weights_lung_pro_cv_multiple.h5')\n",
    "model.save('model_lung_pro_cv_multiple.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_test: (21, 224, 224)\n",
      "shape of X_testing1: (21, 224, 224, 3)\n",
      "shape of X_test_patch: (21, 64, 64)\n",
      "shape of X_testing2: (21, 64, 64, 3)\n",
      "shape of y_test: (21,)\n",
      "21/21 [==============================] - 1s 33ms/step\n",
      "\n",
      "Predicted labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "True labels: [0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "\n",
      "[False False False  True  True  True False False False  True  True  True\n",
      "  True  True  True  True  True  True False False False]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use this cell to test the model (all of the inputs have been given in the second cell)\n",
    "\n",
    "# loading the model\n",
    "\n",
    "#model = load_model('model_lung_pro_cv_multiple.h5')\n",
    "#model.summary()\n",
    "\n",
    "# getting the images for testing\n",
    "\n",
    "file_list2 = os.listdir(test_dir)\n",
    "test_imgs = [test_dir + \"/\" + \"{}\".format(i) for i in file_list2]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "    \n",
    "X_test = []\n",
    "for image in test_imgs:\n",
    "    X_test.append(cv2.resize(cv2.imread(image, cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "X_test = np.array(X_test)\n",
    "X_test = (X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test))\n",
    "#X_test = X_test/255.0\n",
    "print(\"shape of X_test:\", X_test.shape)\n",
    "\n",
    "X_testing1 = []\n",
    "for m in range (len(X_test)):\n",
    "    X_testt = X_test[m]\n",
    "    X_testing1.append(gray2RGB(X_testt))\n",
    "X_testing1 = np.array(X_testing1)\n",
    "print(\"shape of X_testing1:\", X_testing1.shape)\n",
    "\n",
    "# getting the patches for testing\n",
    "\n",
    "file_list3 = os.listdir(test_dir_patch)\n",
    "test_imgs_patch = [test_dir_patch + \"/\" + \"{}\".format(i) for i in file_list3]\n",
    "#print(\"No. of test images = \", len(test_imgs))\n",
    "X_test_patch = []\n",
    "for image in test_imgs_patch:\n",
    "    X_test_patch.append(cv2.resize(cv2.imread(image, cv2.IMREAD_GRAYSCALE), (Patch_SIZE, Patch_SIZE), interpolation=cv2.INTER_CUBIC))\n",
    "\n",
    "X_test_patch = np.array(X_test_patch)\n",
    "print(\"shape of X_test_patch:\", X_test_patch.shape)\n",
    "\n",
    "X_test_final = []\n",
    "for h in range (len(X_test_patch)):\n",
    "    X_test_final.append(read_patch_test(X_test[h], X_test_patch[h], patch_size = (Patch_SIZE, Patch_SIZE)))\n",
    "X_test_final = np.array(X_test_final)\n",
    "\n",
    "X_testing2 = []\n",
    "for m in range (len(X_test_final)):\n",
    "    X_testt = X_test_final[m]\n",
    "    X_testing2.append(gray2RGB(X_testt))\n",
    "X_testing2 = np.array(X_testing2)\n",
    "print(\"shape of X_testing2:\", X_testing2.shape)\n",
    "\n",
    "# getting the true labels for testing\n",
    "\n",
    "df = pandas.read_csv(csvTest)\n",
    "#print('shape of the dataframe:', df.shape)\n",
    "#print(df.head(2))\n",
    "na = df.loc[:,'File']\n",
    "la = df.loc[:,'Progression']\n",
    "na = np.array(na)\n",
    "la = np.array(la)\n",
    "I = np.argsort(na)\n",
    "na = na[I]\n",
    "la = la[I]\n",
    "y_test = la\n",
    "#sns.set(rc={'figure.figsize':(5,4)})\n",
    "#sns.countplot (y_test)\n",
    "#plt.title(\"Labels\")\n",
    "print (\"shape of y_test:\", y_test.shape)\n",
    "\n",
    "# model prediction\n",
    "\n",
    "preds_test = model.predict([X_testing1, X_testing2], verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "predictions_test = preds_test_t [:, 0]\n",
    "print(\"\")\n",
    "print(\"Predicted labels:\", predictions_test)\n",
    "print(\"\")\n",
    "print(\"True labels:\", y_test)\n",
    "print(\"\")\n",
    "com = np.isclose(predictions_test, y_test.T)\n",
    "print (com)\n",
    "#true_prediction_number = 1 * (com == 'True')\n",
    "#print(true_prediction_number)\n",
    "cm = confusion_matrix(y_test, predictions_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
